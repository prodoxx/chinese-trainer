import { interpretChinese } from "./openai-interpret";

interface AudioContext {
	contextPhrase: string;
	trimStart: number; // milliseconds
	trimDuration: number; // milliseconds
}

/**
 * Generate audio context for disambiguated characters
 * Returns a context phrase that forces the correct pronunciation
 */
export async function generateAudioContext(
	hanzi: string,
	pinyin: string,
	meaning: string,
): Promise<AudioContext | null> {
	// First check if this is a known disambiguated character
	const knownContexts = getKnownContexts();
	const key = `${hanzi}-${pinyin.toLowerCase()}`;

	if (knownContexts[key]) {
		return knownContexts[key];
	}

	// For unknown disambiguated characters, use AI to generate context
	try {
		console.log(`   ğŸ¤– Generating audio context for ${hanzi} (${pinyin})...`);

		// Ask OpenAI to generate a short phrase that forces the correct pronunciation
		const response = await fetch("https://api.openai.com/v1/chat/completions", {
			method: "POST",
			headers: {
				Authorization: `Bearer ${process.env.OPENAI_API_KEY}`,
				"Content-Type": "application/json",
			},
			body: JSON.stringify({
				model: "gpt-4-turbo-preview",
				messages: [
					{
						role: "system",
						content: `You are a Chinese language expert. Generate a SHORT 2-character phrase in Traditional Chinese that:
1. Contains the character "${hanzi}" with pronunciation "${pinyin}"
2. Forces Azure TTS to pronounce it with the correct tone
3. The character "${hanzi}" should be at the START of the phrase
4. The phrase should relate to the meaning "${meaning}"

Return ONLY the 2-character phrase, nothing else.`,
					},
					{
						role: "user",
						content: `Generate context phrase for: ${hanzi} (${pinyin}) meaning "${meaning}"`,
					},
				],
				max_tokens: 10,
				temperature: 0.3,
			}),
		});

		if (!response.ok) {
			throw new Error(`OpenAI API error: ${response.status}`);
		}

		const data = await response.json();
		const contextPhrase = data.choices[0]?.message?.content?.trim();

		if (contextPhrase && contextPhrase.includes(hanzi)) {
			// For 2-character phrases, assume first character takes ~600ms
			return {
				contextPhrase,
				trimStart: 0,
				trimDuration: 600,
			};
		}
	} catch (error) {
		console.error("Failed to generate audio context:", error);
	}

	return null;
}

/**
 * Known context phrases for common disambiguated characters
 * These are manually tuned for optimal pronunciation
 */
function getKnownContexts(): Record<string, AudioContext> {
	return {
		// ç´¯ pronunciations
		"ç´¯-lÄ›i": {
			contextPhrase: "ç´¯ç©",
			trimStart: 0,
			trimDuration: 500,
		},
		"ç´¯-lÃ¨i": {
			contextPhrase: "å¥½ç´¯",
			trimStart: 500, // Skip "å¥½"
			trimDuration: 500,
		},

		// é•· pronunciations
		"é•·-zhÇng": {
			contextPhrase: "é•·å¤§",
			trimStart: 0,
			trimDuration: 500,
		},
		"é•·-chÃ¡ng": {
			contextPhrase: "é•·çš„",
			trimStart: 0,
			trimDuration: 500,
		},

		// è¡Œ pronunciations
		"è¡Œ-xÃ­ng": {
			contextPhrase: "è¡Œèµ°",
			trimStart: 0,
			trimDuration: 500,
		},
		"è¡Œ-hÃ¡ng": {
			contextPhrase: "éŠ€è¡Œ",
			trimStart: 500, // Skip "éŠ€"
			trimDuration: 500,
		},

		// å¾— pronunciations
		"å¾—-dÃ©": {
			contextPhrase: "å¾—åˆ°",
			trimStart: 0,
			trimDuration: 500,
		},
		"å¾—-de": {
			contextPhrase: "èµ°å¾—",
			trimStart: 500, // Skip "èµ°"
			trimDuration: 300, // Shorter for neutral tone
		},
		"å¾—-dÄ›i": {
			contextPhrase: "å¾—å»",
			trimStart: 0,
			trimDuration: 500,
		},

		// é‡ pronunciations
		"é‡-zhÃ²ng": {
			contextPhrase: "é‡è¦",
			trimStart: 0,
			trimDuration: 500,
		},
		"é‡-chÃ³ng": {
			contextPhrase: "é‡è¤‡",
			trimStart: 0,
			trimDuration: 500,
		},

		// å¥½ pronunciations
		"å¥½-hÇo": {
			contextPhrase: "å¥½çš„",
			trimStart: 0,
			trimDuration: 500,
		},
		"å¥½-hÃ o": {
			contextPhrase: "å¥½å­¸",
			trimStart: 0,
			trimDuration: 500,
		},

		// å°‘ pronunciations
		"å°‘-shÇo": {
			contextPhrase: "å°‘æ•¸",
			trimStart: 0,
			trimDuration: 500,
		},
		"å°‘-shÃ o": {
			contextPhrase: "å°‘å¹´",
			trimStart: 0,
			trimDuration: 500,
		},

		// ç•¶ pronunciations
		"ç•¶-dÄng": {
			contextPhrase: "ç•¶ç„¶",
			trimStart: 0,
			trimDuration: 500,
		},
		"ç•¶-dÃ ng": {
			contextPhrase: "ç•¶ä½œ",
			trimStart: 0,
			trimDuration: 500,
		},

		// ç›¸ pronunciations
		"ç›¸-xiÄng": {
			contextPhrase: "ç›¸åŒ",
			trimStart: 0,
			trimDuration: 500,
		},
		"ç›¸-xiÃ ng": {
			contextPhrase: "ç›¸ç‰‡",
			trimStart: 0,
			trimDuration: 500,
		},

		// å‚³ pronunciations
		"å‚³-chuÃ¡n": {
			contextPhrase: "å‚³æ’­",
			trimStart: 0,
			trimDuration: 500,
		},
		"å‚³-zhuÃ n": {
			contextPhrase: "å‚³è¨˜",
			trimStart: 0,
			trimDuration: 500,
		},
	};
}

/**
 * Check if a character needs context-based audio generation
 */
export function needsAudioContext(hanzi: string, pinyin: string): boolean {
	// Check if it's in our known list
	const knownContexts = getKnownContexts();
	const key = `${hanzi}-${pinyin.toLowerCase()}`;

	if (knownContexts[key]) {
		return true;
	}

	// Check dictionary for multiple pronunciations
	// This would be done by checking if the character has multiple entries
	// For now, we'll use a simple list of known multi-pronunciation characters
	const multiPronunciationChars = [
		"ç´¯",
		"é•·",
		"è¡Œ",
		"å¾—",
		"é‡",
		"å¥½",
		"å°‘",
		"ç•¶",
		"ç›¸",
		"å‚³",
		"å’Œ",
		"ç‚º",
		"äº†",
		"è‘—",
		"é",
		"çµ¦",
		"è¦",
		"å°‡",
		"èª¿",
		"è½‰",
		"ä¹¾",
		"é›£",
		"åˆ†",
		"ç™¼",
		"ä¸­",
		"é‚„",
		"å ´",
		"ç¨®",
		"åª",
		"ç³»",
	];

	return multiPronunciationChars.includes(hanzi);
}
